{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E6 Planners change how work gets done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's get a ðŸ”¥ kernel ready\n",
    "\n",
    "We're going to create a kernel that includes an embedding generation service â€” so that we can best construct the context that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==0.3.7.dev0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills import FileIOSkill, MathSkill, TextSkill, TimeSkill\n",
    "from semantic_kernel.planning import SequentialPlanner\n",
    "\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(FileIOSkill(), \"fileIO\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "kernel.import_skill(TextSkill(), \"text\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"What day of the week is today, all uppercase?\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"./skills\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterSkill\")\n",
    "#text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translated to French.\"\"\"\n",
    "# ask = \"\"\"Summarize the following: A bear ate an octopus. The octopus was very sad. And the bear wasn't sad at all. A baby got sick by watching this happen.\"\"\"\n",
    "# ask = \"\"\"Translate the following to French: A bear ate an octopus. The octopus was very sad. And the bear wasn't sad at all. A baby got sick by watching this happen.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion, OpenAITextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI backend used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"./plugins-sk\"\n",
    "\n",
    "\n",
    "dt_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"DesignThinking\")\n",
    "bt_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"BusinessThinking\")\n",
    "# text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "# ask = \"\"\"\n",
    "# Tomorrow is Valentine's day. I need to come up with a few date ideas. She speaks French so write it in French.\n",
    "# Convert the text to uppercase.\"\"\"\n",
    "ask = \"\"\"\n",
    "I want to solve a business problem for a pizza shop owner who has a lot of customers who are unhappy.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "I want to solve a business problem for a pizza shop owner who has a lot of customers who are unhappy.\"\"\"\n",
    "original_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing the pizza shop owner is figure out how to get more time back for themself. Often times that time gained can be used for the pizza shop to reinvest in the same way that money saved can be re-leveraged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

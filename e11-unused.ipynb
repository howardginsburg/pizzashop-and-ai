{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E9 Planners and their future promise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==0.3.8.dev0\n",
    "!python -m pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from semantic_kernel.connectors.memory.chroma import ChromaMemoryStore\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", AzureTextEmbedding(\"text-embedding-ada-002\", api_key, endpoint))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "\n",
    "#kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.register_memory_store(memory_store=ChromaMemoryStore(persist_directory='mymemories'))\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's get a ðŸ”¥ kernel ready\n",
    "\n",
    "We're going to create a kernel that includes an embedding generation service â€” so that we can best construct the context that will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that in Example 2 I attempt to load the currently compiled SK locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 (skip to Example 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills import FileIOSkill, MathSkill, TextSkill, TimeSkill\n",
    "from semantic_kernel.planning import SequentialPlanner\n",
    "\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(FileIOSkill(), \"fileIO\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "kernel.import_skill(TextSkill(), \"text\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"What day of the week is today, all uppercase?\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "print(plan.description)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaeda/Documents/GitHub/pizzashop-and-ai/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize given text or any text document : SummarizeSkill.Summarize {'input': \"Tomorrow is Valentine's day. I need to come up with a poem.\"} ['TOPIC']\n",
      "Turn a scenario into a short and entertaining poem. : WriterSkill.ShortPoem {'input': '', 'topic': '$TOPIC'} ['POEM']\n",
      "Translate the input into a language of your choice : WriterSkill.Translate {'input': '$POEM', 'language': 'French'} ['RESULT__POEM_IN_FRENCH']\n",
      "Step: 0\n",
      "Description: Summarize given text or any text document\n",
      "Function: SummarizeSkill.Summarize\n",
      "Input vars: {'input': \"Tomorrow is Valentine's day. I need to come up with a poem.\"}\n",
      "Output vars: ['TOPIC']\n",
      "  Output: Valentine's day tomorrow, need poem.\n",
      "\n",
      "Step: 1\n",
      "Description: Turn a scenario into a short and entertaining poem.\n",
      "Function: WriterSkill.ShortPoem\n",
      "Input vars: {'input': '', 'topic': '$TOPIC'}\n",
      "Output vars: ['POEM']\n",
      "  Output: Roses are red, violets are blue,\n",
      "        Valentine's Day is tomorrow, what to do?\n",
      "        Buy chocolates, flowers, and a card,\n",
      "        Or just stay home and binge-watch \"The Bard.\"\n",
      "        \n",
      "        If you're single, don't you fret,\n",
      "        Treat yourself to a fancy duet\n",
      "\n",
      "Step: 2\n",
      "Description: Translate the input into a language of your choice\n",
      "Function: WriterSkill.Translate\n",
      "Input vars: {'input': '$POEM', 'language': 'French'}\n",
      "Output vars: ['RESULT__POEM_IN_FRENCH']\n",
      "  Output: Les roses sont rouges, les violettes sont bleues,\n",
      "        La Saint-Valentin est demain, que faire ?\n",
      "        Acheter des chocolats, des fleurs et une carte,\n",
      "        Ou rester Ã  la maison et regarder \"The Bard\".\n",
      "        \n",
      "        Si vous Ãªtes cÃ©libataire, ne vous inquiÃ©tez pas,\n",
      "        Offrez-vous un duo de luxe.\n",
      "\n",
      "Final Answer:\n",
      "Les roses sont rouges, les violettes sont bleues,\n",
      "La Saint-Valentin est demain, que faire ?\n",
      "Acheter des chocolats, des fleurs et une carte,\n",
      "Ou rester Ã  la maison et regarder \"The Bard\".\n",
      "\n",
      "Si vous Ãªtes cÃ©libataire, ne vous inquiÃ©tez pas,\n",
      "Offrez-vous un duo de luxe.\n",
      "Expected Answer:\n",
      "Les roses sont rouges, les violettes sont bleues,\n",
      "La Saint-Valentin est demain, que faire ?\n",
      "Acheter des chocolats, des fleurs et une carte,\n",
      "Ou rester Ã  la maison et regarder \"The Bard\".\n",
      "\n",
      "Si vous Ãªtes cÃ©libataire, ne vous inquiÃ©tez pas,\n",
      "Offrez-vous un duo de luxe.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"./skills\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterSkill\")\n",
    "#text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name + \".\" + step._function.name, step._parameters._variables, step._outputs)\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(\"Step:\", index)\n",
    "    print(\"Description:\",step.description)\n",
    "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "    print(\"Input vars:\", step._parameters._variables)\n",
    "    print(\"Output vars:\", step._outputs)\n",
    "    if len(step._outputs) > 0:\n",
    "        print( \"  Output:\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n        \"))\n",
    "\n",
    "    print()\n",
    "print(\"Final Answer:\")\n",
    "print(result)\n",
    "\n",
    "#for step in plan._steps:\n",
    "#    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"./plugins-sk\"\n",
    "\n",
    "\n",
    "#dt_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"DesignThinking\")\n",
    "bt_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"BusinessThinking\")\n",
    "# text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "# ask = \"\"\"\n",
    "# Tomorrow is Valentine's day. I need to come up with a few date ideas. She speaks French so write it in French.\n",
    "# Convert the text to uppercase.\"\"\"\n",
    "ask = \"\"\"\n",
    "I want to solve a business problem for a pizza shop owner who has a lot of customers who are unhappy.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "I want to solve a business problem for a pizza shop owner who has a lot of customers who are unhappy.\"\"\"\n",
    "original_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing the pizza shop owner is figure out how to get more time back for themself. Often times that time gained can be used for the pizza shop to reinvest in the same way that money saved can be re-leveraged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

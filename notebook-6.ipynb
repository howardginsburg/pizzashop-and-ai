{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßë‚Äçüç≥ A kitchen that responds to your ‚ÄúI‚Äôm hungry‚Äù is more than feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan our path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaeda/Documents/GitHub/pizzashop-and-ai/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x1261ed5b0>,\n",
       " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x1261ed4f0>}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from semantic_kernel.connectors.memory.chroma import ChromaMemoryStore\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", AzureTextEmbedding(\"text-embedding-ada-002\", api_key, endpoint))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "\n",
    "kernel.register_memory_store(memory_store=ChromaMemoryStore(persist_directory='mymemories'))\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"./plugins-sk\"\n",
    "consultant_plugin = kernel.import_semantic_skill_from_directory(skills_directory, \"FriendlyConsultant\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "# ask = \"\"\"\n",
    "# Create a business presentation about a hamburger restaurant.\"\"\"\n",
    "# ask = \"\"\"\n",
    "# Create a research interview about a hamburger restaurant business. The focus is on its strengths.\"\"\"\n",
    "# ask = \"\"\"\n",
    "# Create a business presentation about a hamburger restaurant business. The context is that has served the local community of Chicago for 43 years and is famous for chili burgers.\"\"\"\n",
    "ask = \"\"\"\n",
    "Create a marketing plan for a burger restaurant that has served the local community of Chicago for 43 years and is famous for chili burgers.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(\"PLAN \",step.description, \":\", step.skill_name + \".\" + step._function.name, step._parameters._variables, step._outputs)\n",
    "#print(\"LENGTH: \"+len(plan._steps))\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(\"Step:\", index)\n",
    "    print(\"Description:\",step.description)\n",
    "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "    print(\"Input vars:\", step._parameters._variables)\n",
    "    print(\"Output vars:\", step._outputs)\n",
    "    if len(step._outputs) > 0:\n",
    "        print( \"  Output:\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n        \"))\n",
    "\n",
    "    print()\n",
    "# print(\"Final Answer:\")\n",
    "# print(result)\n",
    "\n",
    "# #for step in plan._steps:\n",
    "# #    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "# print(\"Expected Answer:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "#    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What day of the week is today, all uppercase?\n",
      "Step: 0\n",
      "Description: Get the current date.\n",
      "Function: time.today\n",
      "Input vars: {'input': ''}\n",
      "Output vars: ['TODAY']\n",
      "  Output: Monday, 14 August, 2023\n",
      "\n",
      "Step: 1\n",
      "Description: Get the current day of the week\n",
      "Function: time.dayOfWeek\n",
      "Input vars: {'input': '$TODAY'}\n",
      "Output vars: ['DAY_OF_WEEK']\n",
      "  Output: Monday\n",
      "\n",
      "Step: 2\n",
      "Description: Convert a string to uppercase.\n",
      "Function: text.uppercase\n",
      "Input vars: {'input': '$DAY_OF_WEEK'}\n",
      "Output vars: ['RESULT__DAY_OF_WEEK_UPPERCASE']\n",
      "  Output: MONDAY\n",
      "\n",
      "Get the current date. : time today {'_variables': {'input': ''}, '_main_key': 'input'}\n",
      "Get the current day of the week : time dayOfWeek {'_variables': {'input': ''}, '_main_key': 'input'}\n",
      "Convert a string to uppercase. : text uppercase {'_variables': {'input': ''}, '_main_key': 'input'}\n",
      "Expected Answer:\n",
      "MONDAY\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.core_skills import FileIOSkill, MathSkill, TextSkill, TimeSkill\n",
    "from semantic_kernel.planning import SequentialPlanner\n",
    "\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(FileIOSkill(), \"fileIO\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "kernel.import_skill(TextSkill(), \"text\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"What day of the week is today, all uppercase?\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "print(plan.description)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(\"Step:\", index)\n",
    "    print(\"Description:\",step.description)\n",
    "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "    print(\"Input vars:\", step._parameters._variables)\n",
    "    print(\"Output vars:\", step._outputs)\n",
    "    if len(step._outputs) > 0:\n",
    "        print( \"  Output:\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n        \"))\n",
    "\n",
    "    print()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing the pizza shop owner is figure out how to get more time back for themself. Often times that time gained can be used for the pizza shop to reinvest in the same way that money saved can be re-leveraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn a scenario into a short and entertaining poem. : WriterSkills.ShortPoem {'input': '', 'topic': \"Valentine's day\"} ['POEM']\n",
      "Translate the input into a language of your choice : WriterSkills.Translate {'input': '$POEM', 'language': 'French'} ['RESULT__FINAL_POEM']\n",
      "Step: 0\n",
      "Description: Turn a scenario into a short and entertaining poem.\n",
      "Function: WriterSkills.ShortPoem\n",
      "Input vars: {'input': '', 'topic': \"Valentine's day\"}\n",
      "Output vars: ['POEM']\n",
      "  Output: On Valentine's Day, full of cheer,\n",
      "        Cupid's arrows fly far and near.\n",
      "        But my date was a cat,\n",
      "        In a little red hat,\n",
      "        Guess it's love, but just not the right gear!\n",
      "\n",
      "Step: 1\n",
      "Description: Translate the input into a language of your choice\n",
      "Function: WriterSkills.Translate\n",
      "Input vars: {'input': '$POEM', 'language': 'French'}\n",
      "Output vars: ['RESULT__FINAL_POEM']\n",
      "  Output: Le jour de la Saint-Valentin, plein de joie,\n",
      "        Les fl√®ches de Cupidon volent de pr√®s et de loin.\n",
      "        Mais mon rendez-vous √©tait un chat,\n",
      "        Dans un petit chapeau rouge,\n",
      "        Je suppose que c'est de l'amour, mais pas le bon √©quipement !\n",
      "\n",
      "Final Answer:\n",
      "Le jour de la Saint-Valentin, plein de joie,\n",
      "Les fl√®ches de Cupidon volent de pr√®s et de loin.\n",
      "Mais mon rendez-vous √©tait un chat,\n",
      "Dans un petit chapeau rouge,\n",
      "Je suppose que c'est de l'amour, mais pas le bon √©quipement !\n",
      "Expected Answer:\n",
      "Le jour de la Saint-Valentin, plein de joie,\n",
      "Les fl√®ches de Cupidon volent de pr√®s et de loin.\n",
      "Mais mon rendez-vous √©tait un chat,\n",
      "Dans un petit chapeau rouge,\n",
      "Je suppose que c'est de l'amour, mais pas le bon √©quipement !\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "plugins_directory = \"./plugins-sk\"\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(plugins_directory, \"LiterateFriend\")\n",
    "#text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for step in plan._steps:\n",
    "    print(step.description, \":\", step.skill_name + \".\" + step._function.name, step._parameters._variables, step._outputs)\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(\"Step:\", index)\n",
    "    print(\"Description:\",step.description)\n",
    "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "    print(\"Input vars:\", step._parameters._variables)\n",
    "    print(\"Output vars:\", step._outputs)\n",
    "    if len(step._outputs) > 0:\n",
    "        print( \"  Output:\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n        \"))\n",
    "\n",
    "    print()\n",
    "print(\"Final Answer:\")\n",
    "print(result)\n",
    "\n",
    "#for step in plan._steps:\n",
    "#    print(step.description, \":\", step.skill_name, step._function.name, step._state.__dict__)\n",
    "\n",
    "print(\"Expected Answer:\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
